{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech enhancement by Wiener filtering - Voice activity detection and all pole modelling of the vocal tract\n",
    "*Laurent Colbois, Lionel Desarzens  \n",
    "COM-415 Audio and Acoustic Signal Processing course  \n",
    "EPFL 2018-2019*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Abstract***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Review of existing techniques (How thorough ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Algorithm description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We denote $y$ the noisy speech signal to enhance. $y$ is decomposed between a clean speech signal $s$ and a noise signal $n$, i.e. $y = s + n$. The denoising algorithm is supposed to build a good estimate $\\hat{s}$ of $s$. In practice, we build artificially $y$ by adding noise of our choice (either white noise, or noise from another sound file) to a clean speech sample. This allows in particular to control freely the SNR of $y$. The algorithm we use for speech enhancement is called *Iterative Wiener Filtering* and is presented hereafter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Wiener filtering\n",
    "The general approach for the denoising process is by the use of a Wiener filter that we apply in the STFT domain.\n",
    "The main principle of a Wiener filter is the following : given an input signal $x$ and a target signal $d$, the Wiener filter is a linear filter that, when applied on $x[n]$, gives as an output $\\hat{d}$ such that the error $e[n] = \\hat{d} - d$ is minimized in the least square sense. In the context of speech enhanchement, the input signal is $y = s + n$, and the target signal would be $s$. Note that in general $s$ is not actually known; however if one gains some insight on the spectral properties of $s$, a reasonable Wiener filter can be constructed.\n",
    "\n",
    "According to **Cite main article** or **Cite Loizou book**, in the context of speech enhancement a good Wiener filter, given in the frequency domain, is \n",
    "$$H(\\omega) = \\frac{P_s(\\omega)}{P_s(\\omega)+P_n(\\omega)}$$  \n",
    "where $P_s$ and $P_n$ are the power spectral density (PSD) of respectively the speech and the noise. The main focus of this work is to build a good estimation of those PSDs.  \n",
    "\n",
    "The general approach we choose to build those estimations consists in the following steps. \n",
    "> 0. Split the signal in analysis frames (possibly overlapping)\n",
    "> 1. Run the signal through a voice activity detection module (VAD), identify each frame as either speech or noise\n",
    "> 2. If processing a noise frame : compute a noise PSD estimation\n",
    "> 3. If processing a speech frame :  \n",
    "    4.1 Read the noise PSD estimation from previous noise frames  \n",
    "    4.2 Compute the speech PSD estimation  \n",
    "    4.3 Apply the denoising procedure (build and apply the Wiener filter)-> obtain estimate $\\hat{s}$ of $s$  \n",
    "    4.4 Optional : compute a noise PSD estimation for the current frame by considering the residual  $y - \\hat{s}$, that can possibly be considered when filtering future frames \n",
    "    \n",
    "The detail of how the implementation of the VAD algorithm, the noise PSD estimation and the speech PSD estimation are given in the following subsections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Voice Activity Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Feature extraction  \n",
    "1. Energy of the speech low-frequency subband, total energy\n",
    "2. Zero-crossing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Decision model  \n",
    "1. (Statistical optimization)\n",
    "2. Energy ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Smoothing\n",
    "1. Double threshold for inerty\n",
    "2. Local median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Noise PSD estimation\n",
    "All computations are done under the assumption that the noise is white centered gaussian with variance $\\sigma_n^2$. In this case we simply have $P_n(\\omega) = \\sigma_n^2$.\n",
    "\n",
    "**Update rule for $\\sigma$'s**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Speech PSD estimation : all-pole model\n",
    "The estimation of the speech PSD relies on modelling the speech production as an auto-regressive model. **Cite Lim, Oppenheim**. More specifically, the speech signal $s$ is written as \n",
    "$$ s[l] = \\sum\\limits_{k=1}^{p} a_k s[l-k] + g\\cdot w[l] $$  \n",
    "where $g$ is a gain factor, and $w[l]$ is a simple excitation. $p$ is a chosen parameter. For voiced speech, w[l] is modeled as a simple periodic excitation, while it is modeled as white noise for unvoiced speech. This is also equivalent to say the vocal tract acts on the initial exictation as the following transfer function :\n",
    "\n",
    "$$ V(\\omega) = \\frac{g}{1- \\sum\\limits_{k=1}^{p} a_k e^{-jk\\omega}} $$. In this case the PSD \n",
    "$$ P_s(\\omega) = \\frac{g^2}{\\left| 1- \\sum\\limits_{k=1}^{p} a_k e^{-jk\\omega} \\right|^2}$$\n",
    "$$ g^2 \\text{ such that } \\int_{-\\pi}^{\\pi} P_s(\\omega) \\text{d}\\omega = \\sum\\limits_{k=0}^{N-1}y^2[k] - N\\sigma_n^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics  \n",
    "An obvious qualitative way of evaluating the performance of a speech enhancement system is simply to listen to the signal before and after the denoising operation. However we would like to also have a quantitative measure of the efficiency of the algorithm. We choose the two following metrics :\n",
    "\n",
    "> - A posteriori SNR : from the original signal $y$ and speech signal estimation $\\hat{s}$, one can build an estimate $\\hat{n} = y - \\hat{s}$ of the noise signal. This allows to compute the SNR of $\\hat{s}$ with respect to $\\hat{n}$, and to compare it with the true SNR of $s$ with respect to $n$. This SNR a posteriori should be higher than the true SNR if the denoising operation is successful.    \n",
    "\n",
    "\n",
    "> - Intelligibility : even when it increases the SNR, the denoising operation might add some distortion in the speech signal and decrease its intelligibility. In order to get a quantitative measure of intelligibilty, we use a pretrained neural network for classification of speech signal (Google Speech Command Dataset). This network is asked to classify speech signals at various SNR ratios, and we compare its classification certainty for noisy speech and denoised speech. The code for this operation was greatly inspired from [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "\n",
    "<head>\n",
    "<title>evaluation</title>\n",
    "<meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\">\n",
    "<meta name=\"generator\" content=\"bibtex2html\">\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "\n",
    "<!-- This document was automatically generated with bibtex2html 1.98\n",
    "     (see http://www.lri.fr/~filliatr/bibtex2html/),\n",
    "     with the following command:\n",
    "     /usr/bin/bibtex2html evaluation.bib  -->\n",
    "\n",
    "\n",
    "<table>\n",
    "\n",
    "<tr valign=\"top\">\n",
    "<td align=\"right\" class=\"bibtexnumber\">\n",
    "[<a name=\"Mermet:255834\">1</a>]\n",
    "</td>\n",
    "<td class=\"bibtexitem\">\n",
    "Alexis Mermet.\n",
    " Augmenting \"pyroomacoustics\" with machine learning utilities.\n",
    " 2018.\n",
    " SEMESTER_PROJECT.\n",
    "[<a href=\"http://infoscience.epfl.ch/record/255834\">http</a>&nbsp;]\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table><hr><p><em>This file was generated by\n",
    "<a href=\"http://www.lri.fr/~filliatr/bibtex2html/\">bibtex2html</a> 1.98.</em></p>\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
